{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b676684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"D:/hf_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"D:/hf_cache/datasets\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"D:/hf_cache/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2c8d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5542772",
   "metadata": {},
   "source": [
    "# Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4640834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "d:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7908907",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset['train'][0]['article']\n",
    "\n",
    "inputs = tokenizer(\n",
    "    'summarize: ' + sample_text, #tell the model your task is summarization\n",
    "    max_length = 512,\n",
    "    truncation = True, # Automatically cut the remaining part.above 512\n",
    "    return_tensors = 'pt' #Return output as PyTorch(pt) tensors.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6990e56",
   "metadata": {},
   "source": [
    "| Task               | Input Given to Model                   |\n",
    "| ------------------ | -------------------------------------- |\n",
    "| Translation        | `\"translate English to German: Hello\"` |\n",
    "| Summarization      | `\"summarize: Long article...\"`         |\n",
    "| Question Answering | `\"question: Who invented AI?\"`         |\n",
    "| Grammar Fix        | `\"fix grammar: he go school\"`          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb5f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[21603,    10,   301, 24796,  4170,     6,  2789,    41, 18844,    61,\n",
      "          1636,  8929, 16023,  2213,  4173,  6324, 12591,    15, 11391,   592,\n",
      "            12,     3,     9,  2196,  3996,  1755,   770,  8785,   591, 11039,\n",
      "           770,    61, 13462,    38,     3,    88,  5050,   507,    30,  2089,\n",
      "             6,    68,     3,    88, 10419,     7,     8,   540,   751,    31,\n",
      "            17,  4061,     3,     9, 10783,    30,   376,     5,  4173,  6324,\n",
      "         12591,    15,    38,  8929, 16023,    16,    96, 15537,   651, 16023,\n",
      "            11,     8,  5197,    13,     8, 12308,   121,   304,     8, 19142,\n",
      "            13, 29517,  6710,   343,     7,   300,     8,   296,     6,     8,\n",
      "          1021,  7556,   845,     3,    88,    65,   150,  1390,    12,  9030,\n",
      "            17,   449,   112,  1723,   550,    30,  1006,  2948,     6,  3281,\n",
      "            11, 17086,  2251,     5,    96,   196,   278,    31,    17,   515,\n",
      "            12,    36,    80,    13,   273,   151,   113,     6,    38,  1116,\n",
      "            38,    79,   919, 14985,  8247,   805,  1452,     3,     9,  3805,\n",
      "          2100,   443,  1232,    42,   424,  1126,   976,     3,    88,  1219,\n",
      "            46,  3746,  2772,    49,  2283,    48,   847,     5,    96,   196,\n",
      "           278,    31,    17,   317,    27,    31,   195,    36,  1989, 28887,\n",
      "             5,    96,   634,   378,    27,   114,  2611,    33,   378,    24,\n",
      "           583,    81,   335,  7051,  1636,  1335,    11,  3190,     7,    11,\n",
      "          5677,     7,   535,   486, 14985,  6324, 12591,    15,    56,    36,\n",
      "             3,   179,    12, 24068,    16,     3,     9,  2653,     6,   805,\n",
      "             3,     9,  3281,    16,     3,     9, 11943,    42,   217,     8,\n",
      "         12082,   814,    96,  4489,     7,  1625,    10,  2733,  2466,   976,\n",
      "          1083,  1296,  1747,   666,   112,   381,    80,  1974,    30,     8,\n",
      "          1270,  1367,   828,  5059,     5,  9487,    13,   149,     3,    88,\n",
      "            31,   195,  3946,   112, 15754,  3591,    33,   365,  6215,     7,\n",
      "             5,   978,  3102,    11,   452,   343,   141,   150,  1670,    30,\n",
      "           112,  1390,     5,    96,   196,    31,   195,  1728,    43,   128,\n",
      "          1843,    13,  1088,   976,     3,    88,   243,    16,    46,  2772,\n",
      "             5,    96, 12599,  5839,    13,    25,    56,    36,  1183,    81,\n",
      "            34,   535,  6324, 12591,    15,    31,     7,  8783,    45,     8,\n",
      "           166,   874, 16023,  4852,    43,   118,  1213,    16,     3,     9,\n",
      "          2019,  3069,    84,     3,    88,    65,    59,   118,     3,   179,\n",
      "            12,  1586,     5,     3,  4868,   112,  1710, 10393,    11, 20816,\n",
      "             6,     8,  7556,   845,     3,    88,    19,  2627,   112,  1922,\n",
      "             3, 16804,    30,     8,  1591,     5,    96, 24337,    33,   373,\n",
      "           479,    12,   497,     3,    31,  2168,    26,  2213,  1550,   326,\n",
      "             8,  6579,     7,     6,    31,   121,     3,    88,  1219, 19644,\n",
      "           336,   847,     5,    96, 11836,    27,   653,   182,   614,    59,\n",
      "            12,   281,    24,   194,   250,    34,   133,    36,   396,   514,\n",
      "            21,   135,   535,   978,  1251,    91,    53,    38,     8,  4940,\n",
      "         25027,    16,    96, 15537,   651, 16023,    11,     8,  5197,    13,\n",
      "             8, 12308,   121,    19,  7814,  3187,    30,   321,  4458,    13,\n",
      "             8,  9640,    11,     3,    88,    56, 21504,     8,  1075,    16,\n",
      "             8,   336,   192,  4852,     5,  4195,    27,    18,  1649,  1493,\n",
      "            49,   428,   160,  1132,    13, 16023,    31,     7,  1251,  1168,\n",
      "             3,     5,   290,    19,   280,  1909, 16023,     6,   983,     5,\n",
      "            37,  1524,    49,    65,     3, 25403,     3,     9,  1424,  1974,\n",
      "           718,    96,  7008,  7508,  4496,   976,    81,  2291, 17806,  6636,\n",
      "          4320,   102,   697,    11,   112,   520,     6,   788,    21,  1576,\n",
      "           865,    48,   215,     5,   216,    56,    92,  2385,    16,    96,\n",
      "         29835,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ninput_ids\\n\\nNumbers representing words.\\n\\nExample:\\n\\n\"hello world\"\\nâ†’ [8774, 296]\\n\\nattention_mask\\n\\nTells model:\\n\\n1 = real token\\n0 = padding'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs)\n",
    "\n",
    "\n",
    "'''\n",
    "input_ids\n",
    "\n",
    "Numbers representing words.\n",
    "\n",
    "Example:\n",
    "\n",
    "\"hello world\"\n",
    "â†’ [8774, 296]\n",
    "\n",
    "attention_mask\n",
    "\n",
    "Tells model:\n",
    "\n",
    "1 = real token\n",
    "0 = padding'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "642775ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'summarize: LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. Watch I-Reporter give her review of Potter\\'s latest Â». There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December</s>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91bd2195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This model already knows:\\n\\ngrammar\\n\\nlanguage structure\\n\\nsummarization patterns'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
    "\n",
    "'''This model already knows:\n",
    "\n",
    "grammar\n",
    "\n",
    "language structure\n",
    "\n",
    "summarization patterns'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abdbdfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    inputs['input_ids'],\n",
    "    max_length=50, #Maximum length of generated summary\n",
    "    num_beams=4, #Try 4 possible summaries Choose best\n",
    "    early_stopping=True #Stops generation when summary logically ends.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d923b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     8,  1021,  7556,   845,     3,    88,    65,   150,  1390,\n",
       "            12,  9030,    17,   449,   112,  1723,   550,    30,  1006,  2948,\n",
       "             6,  3281,    11, 17086,  2251,     3,     5,     3,    88,    56,\n",
       "            36,     3,   179,    12, 24068,    16,     3,     9,  2653,     6,\n",
       "           805,     3,     9,  3281,    16,     3,     9, 11943,    42,   217]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95e59aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. he will be able to gamble in a casino, buy a drink in a pub or see\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwithout skip_special_tokens=true \\n\\n<pad> <pad> The match ended dramatically </s>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "print(summary)\n",
    "\n",
    "\n",
    "'''\n",
    "without skip_special_tokens=true \n",
    "\n",
    "<pad> <pad> The match ended dramatically </s>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb46a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text,max_len=50,beams=4):\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        'summarize: ' + text,\n",
    "        max_length = 512,\n",
    "        truncation = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        max_length = max_len,\n",
    "        num_beams = beams,\n",
    "        early_stopping = True\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360cd94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inmates with the most severe mental illnesses are incarcerated until they're ready to appear in court. most often, they face drug charges or charges of assaulting an officer. they end up on the ninth floor severely mentally\n"
     ]
    }
   ],
   "source": [
    "article = dataset['train'][1]['article']\n",
    "\n",
    "summary = generate_summary(article,beams=4)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661cc32",
   "metadata": {},
   "source": [
    "# Fine-Tuning Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5141b7",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "   â†“\n",
    "\n",
    "Tokenization\n",
    "\n",
    "   â†“\n",
    "\n",
    "Input + Target labels\n",
    "\n",
    "   â†“\n",
    "\n",
    "Model Training\n",
    "\n",
    "   â†“\n",
    "\n",
    "Loss Calculation\n",
    "\n",
    "   â†“\n",
    "\n",
    "Weight Update\n",
    "\n",
    "   â†“\n",
    "\n",
    "Better Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b040ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = dataset['train'].select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd8d9ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \n",
    "    inputs = ['summarize: '+ doc for doc in examples['article']]\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=512,\n",
    "        truncation = True\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        examples['highlights'],\n",
    "        max_length=128,\n",
    "        truncation = True\n",
    "    )\n",
    "    \n",
    "    model_inputs['labels']=labels['input_ids']\n",
    "    \n",
    "    return model_inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee99ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data = small_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True #Dataset sends a group (batch) of rows together.\n",
    ")\n",
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f872dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    \n",
    "    learning_rate=2e-5,\n",
    "    \n",
    "    per_device_train_batch_size=2,   # small for CPU\n",
    "    per_device_eval_batch_size=2,\n",
    "    \n",
    "    num_train_epochs=1,              # keep small initially\n",
    "    \n",
    "    weight_decay=0.01,\n",
    "    \n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    \n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    \n",
    "    evaluation_strategy=\"no\",        # skip eval for speed\n",
    "    \n",
    "    fp16=False                       # GPU only feature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49bbd9b",
   "metadata": {},
   "source": [
    "| Parameter     | Meaning                |\n",
    "| ------------- | ---------------------- |\n",
    "| learning_rate | how fast model learns  |\n",
    "| batch_size=2  | laptop-friendly memory |\n",
    "| epochs=1      | one pass over data     |\n",
    "| weight_decay  | prevents overfitting   |\n",
    "| logging_steps | print progress         |\n",
    "| fp16=False    | CPU compatibility      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bf1132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collector = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model= model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c06b7f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [04:29<?, ?it/s]\n",
      " 17%|â–ˆâ–‹        | 42/250 [02:31<12:05,  3.49s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m model,\n\u001b[0;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collector\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m'''Trainer handles:\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mâœ… forward pass\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03mâœ… optimization\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "File \u001b[1;32md:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\transformers\\trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\transformers\\trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1967\u001b[0m ):\n\u001b[0;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\transformers\\trainer.py:2911\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2909\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   2910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32md:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\accelerate\\accelerator.py:1966\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collector\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "'''Trainer handles:\n",
    "\n",
    "âœ… forward pass\n",
    "âœ… loss calculation\n",
    "âœ… backpropagation\n",
    "âœ… optimization\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682c93e",
   "metadata": {},
   "source": [
    "1. Encoder reads article\n",
    "2. Decoder predicts summary\n",
    "3. Compare with real summary\n",
    "4. Calculate loss\n",
    "5. Update attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc2206b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('artifacts/tokenizer\\\\tokenizer_config.json',\n",
       " 'artifacts/tokenizer\\\\special_tokens_map.json',\n",
       " 'artifacts/tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"artifacts/model\")\n",
    "tokenizer.save_pretrained(\"artifacts/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0a994",
   "metadata": {},
   "source": [
    "# Pretrained vs Fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59966df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\huggingface_hub\\file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ca6a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = AutoModelForSeq2SeqLM.from_pretrained(\"artifacts/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4943c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_model(model, text):\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        \"summarize: \" + text,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=50,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f257754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE SUMMARY:\n",
      " Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June .\n",
      "Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis .\n"
     ]
    }
   ],
   "source": [
    "test_article = dataset[\"test\"][0][\"article\"]\n",
    "true_summary = dataset[\"test\"][0][\"highlights\"]\n",
    "\n",
    "print(\"TRUE SUMMARY:\\n\", true_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8ff5b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BEFORE TRAINING ---\n",
      "\n",
      "the palestinians signed the ICC's founding Rome Statute in January. the ICC also accepted its jurisdiction over alleged crimes committed in the occupied territories. the ICC opened a preliminary examination into the situation\n",
      "\n",
      "--- AFTER TRAINING ---\n",
      "\n",
      "the palestinians signed the ICC's founding Rome Statute in January. the ICC also accepted its jurisdiction over alleged crimes committed in the occupied territories. the ICC opened a preliminary examination into the situation\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- BEFORE TRAINING ---\\n\")\n",
    "print(generate_with_model(base_model, test_article))\n",
    "\n",
    "print(\"\\n--- AFTER TRAINING ---\\n\")\n",
    "print(generate_with_model(trained_model, test_article))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30e354",
   "metadata": {},
   "source": [
    "# Evaluate Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74126a79",
   "metadata": {},
   "source": [
    "ROUGE = Recall-Oriented Understudy for Gisting Evaluation\n",
    "\n",
    "It measures how similar your generated summary is to the human-written summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325237b",
   "metadata": {},
   "source": [
    "| Metric  | Meaning                       |\n",
    "| ------- | ----------------------------- |\n",
    "| ROUGE-1 | word overlap                  |\n",
    "| ROUGE-2 | phrase overlap                |\n",
    "| ROUGE-L | sentence structure similarity |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d64bb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_24340\\865042330.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric(\"rouge\")\n",
      "d:\\TransformerSummarizer\\summarizer\\lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d57e7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, num_samples=50):\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "\n",
    "        article = dataset[\"test\"][i][\"article\"]\n",
    "        true_summary = dataset[\"test\"][i][\"highlights\"]\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            \"summarize: \" + article,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=50,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        pred_summary = tokenizer.decode(\n",
    "            outputs[0],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        predictions.append(pred_summary)\n",
    "        references.append(true_summary)\n",
    "\n",
    "    results = rouge.compute(\n",
    "        predictions=predictions,\n",
    "        references=references\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43d2b86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': AggregateScore(low=Score(precision=0.2792186771007231, recall=0.29468321511191997, fmeasure=0.28257986593597795), mid=Score(precision=0.3185451989817666, recall=0.3373348577705798, fmeasure=0.3199628192125831), high=Score(precision=0.35793511071305434, recall=0.3802107844461455, fmeasure=0.3549506196486023)), 'rouge2': AggregateScore(low=Score(precision=0.09716931887432873, recall=0.10408049257874563, fmeasure=0.09888870543372635), mid=Score(precision=0.13046343534250726, recall=0.13826674269561823, fmeasure=0.13053908138963083), high=Score(precision=0.16448057421086426, recall=0.17358430253014573, fmeasure=0.16239301968749695)), 'rougeL': AggregateScore(low=Score(precision=0.2076877861844154, recall=0.220030705015694, fmeasure=0.2114717887856373), mid=Score(precision=0.24016090488535685, recall=0.25499034872618603, fmeasure=0.2414675921975874), high=Score(precision=0.2747611558099274, recall=0.2925878982878196, fmeasure=0.27202877950667786)), 'rougeLsum': AggregateScore(low=Score(precision=0.22957465321031217, recall=0.24747585341252112, fmeasure=0.23400816218764325), mid=Score(precision=0.2669369348296314, recall=0.28296328362247514, fmeasure=0.2684209261857389), high=Score(precision=0.30884795065403353, recall=0.3226005078927766, fmeasure=0.30525332885117074))}\n",
      "{'rouge1': AggregateScore(low=Score(precision=0.2792186771007231, recall=0.29468321511191997, fmeasure=0.28257986593597795), mid=Score(precision=0.3185451989817666, recall=0.3373348577705798, fmeasure=0.3199628192125831), high=Score(precision=0.35793511071305434, recall=0.3802107844461455, fmeasure=0.3549506196486023)), 'rouge2': AggregateScore(low=Score(precision=0.09716931887432873, recall=0.10408049257874563, fmeasure=0.09888870543372635), mid=Score(precision=0.13046343534250726, recall=0.13826674269561823, fmeasure=0.13053908138963083), high=Score(precision=0.16448057421086426, recall=0.17358430253014573, fmeasure=0.16239301968749695)), 'rougeL': AggregateScore(low=Score(precision=0.2076877861844154, recall=0.220030705015694, fmeasure=0.2114717887856373), mid=Score(precision=0.24016090488535685, recall=0.25499034872618603, fmeasure=0.2414675921975874), high=Score(precision=0.2747611558099274, recall=0.2925878982878196, fmeasure=0.27202877950667786)), 'rougeLsum': AggregateScore(low=Score(precision=0.22957465321031217, recall=0.24747585341252112, fmeasure=0.23400816218764325), mid=Score(precision=0.2669369348296314, recall=0.28296328362247514, fmeasure=0.2684209261857389), high=Score(precision=0.30884795065403353, recall=0.3226005078927766, fmeasure=0.30525332885117074))}\n"
     ]
    }
   ],
   "source": [
    "base_scores = evaluate_model(base_model, dataset)\n",
    "print(base_scores)\n",
    "trained_scores = evaluate_model(trained_model, dataset)\n",
    "print(trained_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21225ad2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
